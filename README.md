# **End-to-End RAG App using AWS Bedrock, LangChain & Streamlit**

This project demonstrates how to build a complete **Retrieval-Augmented Generation (RAG)** system using:

* **AWS Bedrock** for LLMs & embeddings
* **LangChain** for orchestration and retrieval pipelines
* **Streamlit** for a clean, interactive UI

The application allows users to **upload documents**, **create embeddings**, **store vectors**, and **query them with Bedrock models** â€” enabling accurate, context-aware answers.

---

## ğŸš€ **Features**

### ğŸ”¹ **1. Document Ingestion**

* Upload PDFs, text files, or multiple documents.
* Extracts and preprocesses text automatically.

### ğŸ”¹ **2. Vector Embeddings with AWS Bedrock**

* Uses Bedrock embedding models to generate document embeddings.
* Stores vectors in an in-memory or external vector database (depending on your setup).

### ğŸ”¹ **3. RAG Pipeline using LangChain**

* Implements retrieval chains.
* Fetches relevant chunks based on user queries.
* Sends context + query to an AWS Bedrock LLM for grounded answers.

### ğŸ”¹ **4. Streamlit Frontend**

* Clean and interactive UI.
* Upload docs, run queries, inspect responses.
* Real-time outputs and debugging sidebar.

---

## ğŸ› ï¸ **Tech Stack**

| Component                 | Technology                       |
| ------------------------- | -------------------------------- |
| LLM & Embeddings          | **AWS Bedrock**                  |
| Retrieval & Orchestration | **LangChain**                    |
| UI                        | **Streamlit**                    |
| Vector Storage            | FAISS / In-memory (configurable) |
| Backend                   | Python 3.x                       |

---

## ğŸ“‚ **Project Structure**

```
ğŸ“¦ rag-bedrock-app
â”œâ”€â”€ app.py                 # Streamlit application
â”œâ”€â”€ config.py              # AWS & Bedrock configuration
â”œâ”€â”€ ingestion.py           # Document loader & chunker
â”œâ”€â”€ vectorstore.py         # Vector DB logic
â”œâ”€â”€ rag_pipeline.py        # LangChain RAG chain
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ **Setup Instructions**

### **1. Clone the repository**

```bash
git clone https://github.com/your-username/rag-bedrock-app.git
cd rag-bedrock-app
```

### **2. Install dependencies**

```bash
pip install -r requirements.txt
```

### **3. Configure AWS Credentials**

Make sure your environment has:

```
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=
```

Also ensure Bedrock access is enabled in your AWS console.

### **4. Run the Streamlit App**

```bash
streamlit run app.py
```

---

## ğŸ§ª **How It Works**

1. User uploads documents.
2. Text is chunked and embedded using Bedrock Embedding Model.
3. Vectors stored in vector DB.
4. User enters a question.
5. Retriever fetches top-k relevant chunks using similarity search.
6. Context + query sent to Bedrock LLM.
7. Final answer is presented in the UI.

---

## ğŸ¤ **Contributing**

Pull requests are welcome! Feel free to open issues for improvements or feature suggestions.

---

## ğŸ“œ **License**

MIT License.

---
